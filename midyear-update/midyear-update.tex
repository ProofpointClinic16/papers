%%% Clinic Statement of Work Template

%%% !!! HMC STUDENTS SHOULD REMOVE THE FOLLOWING COPYRIGHT NOTICE FROM
%%% !!! FINAL SUBMISSIONS.

%%% Copyright (C) 2004-2015 Department of Mathematics, Harvey Mudd College.
%%%
%%% This file is part of the hmcclinic class document provided to
%%% HMC mathematics students.
%%%
%%% See the COPYING document, which should accompany this
%%% distribution, for information about distribution and
%%% modification of the document and its components.

%%% !!! END COPYRIGHT NOTICE.


%%% Clinic reports use the hmcclinic class, which should be located
%%% somewhere in TeX's search path.

%%% You must set a document-class option to tell the class what
%%% department your report will be for.
\documentclass[cs,midyearupdate]{hmcclinic}
\usepackage{enumitem, graphicx, fancyhdr}

%% Supported department classes are
%%
%%    biology
%%    computer-science
%%    chemistry
%%    engineering
%%    mathematics
%%    physics

%% For your Statement of Work, use "proposal", as set above.


%%% The major difference between the Statement of Work and a midyear
%%% or final report is that the statement of work is typeset as an
%%% article, which means that the highest level of structural
%%% division available to you is \section rather than \chapter.

%%% There are also some changes in pagination styles and content
%%% that reflect the briefer nature of the proposal.  For example,
%%% in the longer reports, you use \frontmatter, \mainmatter, and
%%% \backmatter to separate some sections of the report from
%%% others.  In the statement of work, you don't need those
%%% commands, as no such division is necessary.

%%% Other packages needed by your document may be loaded here.
% \usepackage{url}              % For formatting URLs and other web or
                                % file references.

%%% Provide additional context around errors. 
\setcounter{errorcontextlines}{1000}


%%% Information about this document.

%%% I find it most useful to put identifying information about a
%%% document near the top of the preamble.  Technically, this
%%% information must precede the \maketitle command, which often
%%% appears immediately after the beginning of the document 
%%% environment.  Placing it near the top of the document makes it
%%% easier to identify the document, and keeps it out from getting
%%% mixed up with the real meat of the document.

%%% We use the same set of commands for specifying information about
%%% the people involved with the project that are used in the longer
%%% reports, so you can copy most of this information directly into
%%% your midyear and final reports.

%%% So, some questions.

%% What is the name of the company or organization sponsoring your project?
\sponsor{Proofpoint, Inc.}

%% What is the title of your report?
\title{Predicting Malicious URLs}

%% Who are the authors of the report (your team members)?  (Separate
%% names with \and.)
\author{Vidushi Ojha (Project Manager) \and Aidan Cheng \and Kevin Herrera \and Carli Lessard}

%% What is your faculty advisor's name?  (Again, separate names with
%% \and, if necessary.)
\advisor{Elizabeth Sweedyk}

%% Liaison's name or names?
\liaison{Thomas Lynam \and Mike Morris}

%% Did you have an outside consultant help you with this project?  Put
%% their names in the \consultant command.
%\consultant{Joseph Jones}

%%% End of information section.

%%% New commands and environments.

%%% You can define your own commands and environments here.  If you
%%% have a lot of material here, you might want to consider splitting
%%% the commands and environments into a separate ``style'' file that
%%% you load with \usepackage.

\newcommand{\coolcommand}[1]{#1 is cool.} % Lets everyone know that
                                % the person or thing that you provide
                                % as the argument to the command is
                                % cool.


%%% Some theorem-like command definitions.

%%% The \newtheorem command comes from the amsthm package.  That
%%% package is *not* automatically loaded by the class file, so if
%%% you choose to use these commands, you'll need to specify the
%%% "amsthm" document-class option.

%%% Note that these definitions have changed from the version in the
%%% sample report document by dropping the ``within'' argument.  See
%%% Gratzer's _Math into LaTeX_ or the AMS-LaTeX documentation for
%%% more details.

% \newtheorem{thm}{Theorem}
% \newtheorem{Theo1}{Theorem}
% \newtheorem{Theo2}{Theorem}
% \newtheorem{Lemma}{Lemma}


%%% If you find that some words in your document are being hyphenated
%%% incorrectly, you can specify the correct hyphenation using the
%%% \hyphenation command.  Note that words are separated by
%%% whitespace, as shown below.

\hyphenation{ap-pen-dix wer-ther-i-an}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LO,RE]{\textbf \thepage}

%%% The start of the document!

%% The document environment is the main environment in any LaTeX
%% document.  It contains other environments, as well as your text.

\begin{document}

%%% In a longer document (such as your midterm and final reports),
%%% you would have separate \frontmatter, \mainmatter, and
%%% \backmatter commands to define some large chunks of your
%%% document.  For the Statement of Work, which is a short document,
%%% we don't need these commands.

%%% Your Statement of Work begins with a title page.  The title page
%%% is formatted by commands in the document class file, so you
%%% don't need to worry about what it looks like -- just putting the
%%% \maketitle command in your document (and filling in the necessary
%%% information for the identification commands above) is enough.
\maketitle

% \tableofcontents

%%% In a longer document or an article being submitted to a journal
%%% or conference, you would probably have an abstract that
%%% summarized the purpose of the document.  We don't need that for
%%% a Statement of Work.

%%% Similarly, in longer documents you would probably have commands
%%% to include a table of contents and lists of figures or tables.
%%% For a short document such as the Statement of Work, we don't
%%% need these commands.


%%% Content.

%%% For smaller documents---especially those you're writing by
%%% yourself---you might write your entire report using a single LaTeX
%%% source file.  For larger documents, we recommend that you split
%%% the source file into several separate, smaller files.  The smaller
%%% files are ``included'' into your main, or ``master'' document
%%% using \include commands.  See the template file for the Clinic
%%% reports for more details on how to split a LaTeX project into
%%% smaller files.


%%% The body of your Statement of Work should appear here.  See
%%% Chapter 4 in _The Mathematics Clinic in Brief: A Handbook_ for
%%% more details on what you should include in a Statement of Work.

\newpage

%%%

\section{Introduction}

Proofpoint is a cybersecurity company that provides security and data protection solutions to other companies. Amongst their many products, they provide an inbound email URL screening service that scans URLs embedded in clients' emails, and determines whether they lead to sites containing malware. Proofpoint's current solution redirects every URL embedded in an email through their servers, where they employ a filter to distinguish between URLs that should and should not be blocked. If their filter determines that the URL is suspicious, the URL is sent to Proofpoint's sandboxing environment for further testing. Sandboxing is an expensive process, and it is infeasible to sandbox most, or even many, of the billions of URLs Proofpoint's security suite sees every day. Thus, the Proofpoint Clinic team aims to improve the accuracy of the filter and decrease the number of URLs sandboxed, avoiding the expensive operation as much as possible.

%%%

\section{Goals}

The goals of the project are to create a classifier that classifies a URL as either clean or malicious, or indicates that the URL should be sandboxed. The classifier must satisfy the following system requirements.

\begin{itemize} \itemsep0em
\item For any given input URL, the system returns a score between 0 and 1, where the score indicates the probability of the URL being malicious.
\item Using the above score, each sample will be classified as either malicious, clean, or in an intermediate zone where it ought to be sandboxed for further investigation. The classification will be based on some threshold values.
\item Our model will explain how the score was assigned, for instance by pointing to characteristics of the URL that make it more likely that it is malicious.
\end{itemize}

%%%

\section{Current Progress}

\subsection{Support Vector Machines}

Support Vector Machines (SVMs) have been shown to be effective classifiers for text classification problems. We used an open-source SVM classifier, scikit-learn, on our data. The major problem we encountered was that training was slow, and the more features and training data we used, the slower it became. When we limited features and training time, the SVM did not produce meaningful predictions. Furthermore, SVMs are intended to be used offline. We anticipate there would be considerable overhead required to build an SVM that operates online. Because of this, working on a classifier using an SVM is not a priority for our team at the moment.

\subsection{Naive Bayes}

\subsubsection{Open-source implementation}

We first used open-source code to implement a Naive Bayes classifier that classifies a URL as clean or malicious. The features employed in this classification are tokens extracted from the URL: for an input URL, every section between a forward slash character (\texttt{`/'}) and every section between a period (\texttt{`.'}) was treated as a separate feature of the URL. We also used 4-grams as features, which means taking every sequence of 4 characters as a feature. The classifier produced a probability for the sample belonging to each class (clean or malicious), and we took the higher probability as the label assigned to the sample. In this way, we got the following results:

\texttt{\\
Caught: 105967 (76.8\% of all samples) \\
Missed: 32015 (23.2\% of all samples) \\
Malicious missed: 2904 (46.3\% of all malicious samples)}
\\\\
From this, we can see that the accuracy is relatively high: we are correctly categorizing almost 77\% of samples. However, for this project, we are most interested in not letting malicious samples slip by. In this respect, we are missing 46.3\% of samples, suggesting we could improve in this metric. In comparison, Proofpoint's existing solution using a linear regression model misses only 19\% of the malicious samples.

\subsubsection{Scikit-learn implementation}

Due to some complications with the above implementation, we also tried using the well-documented scikit-learn Naive Bayes source code. For the first few experiments, we used a Multinomial Naive Bayes classifier, and ran a 6-fold testing technique. (This means splitting the data set into six, training on five of them, and testing on the one holdout. This process is repeated six times.) The features used in this classifier were the character 4-grams referred to above. In this case, the results were:

\texttt{\\
Caught: 128162 (92.9\% of all samples) \\
Missed: 9821 (7.1\% of all samples) \\
Malicious missed: 3904 (62.3\% of all malicious samples)}
\\\\
As we can see, this implementation produces better accuracy results, but is worse in terms of catching malicious samples. We believe, however, that this is due to only having used 4-grams as features. Because of the better documentation and support, we intend to continue working with this Naive Bayes implementation.

\subsection{TensorFlow}

In order to take advantage of the next growing trend in machine learning, deep learning, we began researching into some deep learning software packages offered by open source libraries. Google has an open source library, TensorFlow, that provides implementations of deep learning classifiers. TensorFlow has been used for spam classification, which suggested that it could be useful in our project. Using an existing spam classifier, we constructed a classifier for our data. We currently use tokenization on the URL to generate the features that we give the classifier, tokenizing on characters such as slashes and periods, similar to what was done in the Naive Bayes portion of our project. We train our classifier for a set number of iterations, and then classify new data to see the classifier's performance in terms of precision and accuracy. One downside of our current classification method is that it only outputs its prediction of whether a URL is malicious or not. It would be more helpful in our project if the classifier output a probability of whether a URL is malicious in order to use probability thresholds to determine whether the URL should be sandboxed or not.

%%%

\section{Future Work}

\subsection{Naive Bayes}

We intend to continue working with the scikit-learn implementation of the Naive Bayes classifier, since this offers many more options to explore than the previous implementation we were using. In particular, we intend to investigate the different types classifiers available. In addition, scikit-learn makes it straightforward to add different types of features to the pipeline of the classifier. Currently, we are only using the character 4-grams, but we intend to look into adding more features around the string of the URL itself as well as around other data we get from Proofpoint. See the appendix for more details.

Notably, we have yet to implement any kind of thresholding that would give us an indication of when URLs ought to be sandboxed. We hope to achieve better results on our data set before moving on to estimating thresholds.

\subsection{TensorFlow}

The TensorFlow open source code we are currently using gives room for custom parameter setting, such as the maximum number of features being used within the classifier, so next semester we plan on thoroughly testing these customizable parameters within our classifier in order to determine which changes yield the fastest and best results. Maximum number of features used is one of the parameters that we are allowed to change; thus, we will test which features and number of features improve performance. We will also test how long we should be training our classifier by analyzing the cost-benefit of spending different amounts of iterations on the training of the classifier. Most importantly, TensorFlow provides a variety of optimization algorithms to use, which differ in how they minimize the error of classifications. We will test these algorithms to determine which one works the best for our classification purposes.

%%%

\newpage

\section{Appendix}

A more detailed list of the experiments we plan to perform for Naive Bayes is given below.
\\\\
\textbf{Classifiers}
\begin{itemize} \itemsep0em
\item Multinomial (current) -- uses how frequently a feature is associated with a particular class
\item Bernoulli -- uses whether a feature is present or not
\item Gaussian -- assumes all features have a normal distribution
\end{itemize}


\noindent \textbf{Features}
\begin{itemize} \itemsep0em
\item Tokenization on punctuation of the URL (as in our previous classifier)
\item IP address associated with email
\item Number of messages sent from this IP address before
\end{itemize}

%%%

%\section{References}
%
%\hangindent=2em
%\hangafter=1
%Ma, Justin, Lawrence K. Saul, Stefan Savage, and Geoffrey M. Voelker. ``Beyond Blacklists.'' \textit{15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, 2009, New York, USA. Unpublished conference paper. UCSD Library, 2016. Web.
%
%\hangindent=2em
%\hangafter=1
%\noindent ``Multi-Layer Neural Network.'' \textit{Unsupervised Feature Learning and Deep Learning Tutorial.} Stanford University. Accessed 4 October 2016, \url{http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/}.
%
%\hangindent=2em
%\hangafter=1
%\noindent Sculley, D., and Gabriel Wachman M. ``Relaxed Online SVMs in the TREC Spam Filtering Track.'' \textit{16th Text Retrieval Conference}, 2007, Maryland, USA. Unpublished conference paper. Tufts University Library, 2016. Web.

\newpage



%%% Appendices.

%%% For your Statement of Work, you probably won't have any
%%% appendices, but you could include some if you really needed to.

%%% The appendices are delineated with the \appendix command.
%%% Individual appendices are begun with the standard \chapter or
%%% \section commands.  In our example, we'll \include them just as we
%%% did other chapters.

%%% Even in a relatively short document such as your statement of
%%% work, you might need to have appendices.  If so, uncomment
%%% the \appendix command and add them below (remember, the
%%% top-level structural command in this format is section).

% \appendix

%%% Bibliography.

%%% BibTeX is the tool to use for citations and layout of your
%%% bibliography.  Instead of having to type ``[5]'' or ``(Jones,
%%% 1968)'' (and keep track of which citation is which and renumber
%%% them as you add more references to your bibilography), you use
%%% special commands that allow BibTeX and LaTeX to automatically put
%%% the correct information in the right place.

%%% Section 5.6 in _The Mathematics Clinic in Brief: A Handbook_,
%%% talks about using BibTeX to format your bibliography and
%%% citations.

%%% Depending on your field, it may or may not be appropriate to list
%%% references for which you haven't included specific citations.  If
%%% your field sanctions such practices, or if you just want to get an
%%% idea of what you have in your bibliography file, you can include
%%% everything with the \nocite{*} command.
\nocite{*} 


%%% The appearance of your bibliography and citations in your text are
%%% defined by a combination of any bibliography-related LaTeX
%%% packages (such as natbib, harvard, or chicago) and the particular
%%% bibliography style file that you load with the \bibliographystyle
%%% command.  Bibliography-style files end in .bst; you can find them
%%% by searching your file system using whatever tools you have for
%%% doing searches.  (On most modern Unices, ``locate .bst'' will give
%%% you an idea of what's available.)

\bibliographystyle{hmcmath}

%%% The particular bibliography data file or files that you want to
%%% use are specified with the \bibliography file.  Multiple files are
%%% separated by commas.

%%% You might want to use multiple bibliography (or ``bib'') files if
%%% you had a master bib file containing references you use again and
%%% again, and another containing only records for references for a
%%% particular project.

%%% Many people create a single, large bib file that they use for
%%% everything they write.  That approach requires you to \cite every
%%% reference that you want to use in your document -- using
%%% \nocite{*} with a huge bibliography database will give you a large
%%% bibliography containing many references you haven't consulted for
%%% your particular document!

\bibliography{sample}


%%% Glossary or Index.

%%% Having a glossary or index in a statement of work is overkill.
%%% Just define your terms in the text and you'll be fine.

\end{document}
